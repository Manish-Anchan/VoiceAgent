<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Genie - Voice Tutor</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Arial', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: #333;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 2rem;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 500px;
            width: 90%;
            text-align: center;
        }

        .header {
            margin-bottom: 2rem;
        }

        .header h1 {
            color: #667eea;
            font-size: 2.5rem;
            margin-bottom: 0.5rem;
        }

        .header p {
            color: #666;
            font-size: 1.1rem;
        }

        .status {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 1rem;
            margin: 1rem 0;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: 500;
        }

        .status.listening {
            background: linear-gradient(45deg, #ff9a9e, #fecfef);
            color: #fff;
        }

        .status.speaking {
            background: linear-gradient(45deg, #a8edea, #fed6e3);
            color: #333;
        }

        .status.processing {
            background: linear-gradient(45deg, #ffecd2, #fcb69f);
            color: #333;
        }

        .mic-button {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            font-size: 2rem;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 1rem;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }

        .mic-button:active {
            transform: scale(0.95);
        }

        .mic-button.active {
            animation: pulse 1.5s infinite;
            background: linear-gradient(135deg, #28a745, #20c997);
        }

        .mic-button.listening {
            animation: pulse-red 1.5s infinite;
            background: linear-gradient(135deg, #ff6b6b, #ee5a24);
        }

        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(40, 167, 69, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(40, 167, 69, 0); }
            100% { box-shadow: 0 0 0 0 rgba(40, 167, 69, 0); }
        }

        @keyframes pulse-red {
            0% { box-shadow: 0 0 0 0 rgba(255, 107, 107, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 107, 107, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 107, 107, 0); }
        }

        .conversation {
            max-height: 300px;
            overflow-y: auto;
            margin: 1rem 0;
            text-align: left;
        }

        .message {
            margin: 0.5rem 0;
            padding: 0.75rem;
            border-radius: 10px;
        }

        .message.user {
            background: #e3f2fd;
            margin-left: 2rem;
        }

        .message.genie {
            background: #f3e5f5;
            margin-right: 2rem;
        }

        .message .role {
            font-weight: bold;
            margin-bottom: 0.25rem;
        }

        .user .role {
            color: #1976d2;
        }

        .genie .role {
            color: #7b1fa2;
        }

        .controls {
            margin-top: 1rem;
        }

        .control-button {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 5px;
            padding: 0.5rem 1rem;
            margin: 0.25rem;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .control-button:hover {
            background: #e9ecef;
        }

        .error {
            background: #ffebee;
            color: #c62828;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
        }

        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-top: 3px solid #667eea;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üßû‚Äç‚ôÇÔ∏è Genie</h1>
            <p>Your friendly voice tutor</p>
        </div>

        <div id="status" class="status">
            Click the microphone to start continuous listening!
        </div>

        <div id="error" class="error" style="display: none;"></div>

        <button id="micButton" class="mic-button">
            üé§
        </button>

        <div class="controls">
            <button id="clearButton" class="control-button">Clear Conversation</button>
            <button id="stopButton" class="control-button">Stop Speaking</button>
        </div>

        <div id="conversation" class="conversation"></div>
    </div>

    <script>
        class VoiceTutor {
            constructor() {
                this.isListening = false;
                this.isSpeaking = false;
                this.isProcessing = false;
                this.continuousMode = false;
                this.recognition = null;
                this.currentAudio = null;
                this.history = [];
                this.silenceTimer = null;
                
                this.initElements();
                this.initSpeechRecognition();
                this.bindEvents();
            }

            initElements() {
                this.statusEl = document.getElementById('status');
                this.errorEl = document.getElementById('error');
                this.micButton = document.getElementById('micButton');
                this.clearButton = document.getElementById('clearButton');
                this.stopButton = document.getElementById('stopButton');
                this.conversationEl = document.getElementById('conversation');
            }

            initSpeechRecognition() {
                if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                    this.showError('Speech recognition is not supported in this browser. Please use Chrome or Edge.');
                    return;
                }

                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                this.recognition = new SpeechRecognition();
                
                this.recognition.continuous = true;
                this.recognition.interimResults = true;
                this.recognition.lang = 'en-US';

                this.recognition.onstart = () => {
                    this.isListening = true;
                    this.updateUI();
                };

                this.recognition.onresult = (event) => {
                    let finalTranscript = '';
                    
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript;
                        }
                    }
                    
                    if (finalTranscript.trim()) {
                        // Clear any existing silence timer
                        if (this.silenceTimer) {
                            clearTimeout(this.silenceTimer);
                            this.silenceTimer = null;
                        }
                        
                        // Don't process if we're already speaking or processing
                        if (!this.isSpeaking && !this.isProcessing) {
                            this.handleUserInput(finalTranscript.trim());
                        }
                    }
                };

                this.recognition.onerror = (event) => {
                    console.log('Speech recognition error:', event.error);
                    
                    // Handle different error types
                    switch(event.error) {
                        case 'network':
                            // Network errors are often temporary
                            console.log('Network error, attempting restart...');
                            setTimeout(() => {
                                if (this.continuousMode) {
                                    this.restartListening();
                                }
                            }, 2000);
                            break;
                            
                        case 'no-speech':
                        case 'audio-capture':
                            // These are normal in continuous mode
                            if (this.continuousMode) {
                                this.restartListening();
                                return;
                            }
                            break;
                            
                        case 'not-allowed':
                            this.showError('Microphone access denied. Please allow microphone permissions and refresh the page.');
                            this.continuousMode = false;
                            break;
                            
                        case 'service-not-allowed':
                            this.showError('Speech recognition service not available. Please ensure you\'re using HTTPS or localhost.');
                            this.continuousMode = false;
                            break;
                            
                        default:
                            // For other errors, try to restart after a delay
                            console.log(`Handling error: ${event.error}`);
                            setTimeout(() => {
                                if (this.continuousMode && !this.isSpeaking && !this.isProcessing) {
                                    this.restartListening();
                                }
                            }, 1000);
                            break;
                    }
                    
                    this.isListening = false;
                    this.updateUI();
                };

                this.recognition.onend = () => {
                    this.isListening = false;
                    
                    // Restart listening if in continuous mode and not speaking/processing
                    if (this.continuousMode && !this.isSpeaking && !this.isProcessing) {
                        setTimeout(() => {
                            this.restartListening();
                        }, 100);
                    } else {
                        this.updateUI();
                    }
                };
            }

            bindEvents() {
                this.micButton.addEventListener('click', () => {
                    if (this.continuousMode) {
                        this.stopContinuousListening();
                    } else {
                        this.startContinuousListening();
                    }
                });

                this.clearButton.addEventListener('click', () => {
                    this.clearConversation();
                });

                this.stopButton.addEventListener('click', () => {
                    this.stopSpeaking();
                });
            }

            async checkNetworkAndPermissions() {
                // Check network connectivity
                if (!navigator.onLine) {
                    this.showError('No internet connection. Please check your network.');
                    return false;
                }

                // Check microphone permissions
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    stream.getTracks().forEach(track => track.stop()); // Stop the stream immediately
                    return true;
                } catch (error) {
                    this.showError('Microphone access required. Please allow microphone permissions.');
                    return false;
                }
            }

            async startContinuousListening() {
                if (!this.recognition) return;
                
                // Check network and permissions first
                const canStart = await this.checkNetworkAndPermissions();
                if (!canStart) return;
                
                this.continuousMode = true;
                this.hideError();
                
                try {
                    this.recognition.start();
                } catch (error) {
                    console.log('Failed to start recognition:', error);
                    this.showError('Failed to start speech recognition. Please try again.');
                    this.continuousMode = false;
                }
            }

            stopContinuousListening() {
                this.continuousMode = false;
                if (this.recognition && this.isListening) {
                    this.recognition.stop();
                }
                if (this.silenceTimer) {
                    clearTimeout(this.silenceTimer);
                    this.silenceTimer = null;
                }
            }

            restartListening() {
                if (!this.continuousMode || this.isSpeaking || this.isProcessing) return;
                
                // Add a small delay and check network
                setTimeout(async () => {
                    if (!navigator.onLine) {
                        console.log('No network, delaying restart...');
                        setTimeout(() => this.restartListening(), 5000);
                        return;
                    }
                    
                    try {
                        this.recognition.start();
                    } catch (error) {
                        console.log('Recognition restart failed:', error.message);
                        // If it fails, try again after a longer delay
                        if (this.continuousMode) {
                            setTimeout(() => this.restartListening(), 3000);
                        }
                    }
                }, 500);
            }

            async handleUserInput(transcript) {
                // Pause listening while processing
                if (this.continuousMode && this.isListening) {
                    this.recognition.stop();
                }

                this.addMessage('user', transcript);
                this.isProcessing = true;
                this.updateUI();

                try {
                    const response = await this.getAIResponse(transcript);
                    this.addMessage('genie', response);
                    
                    // Set speaking state before TTS
                    this.isSpeaking = true;
                    this.updateUI();
                    
                    await this.speakResponse(response);
                } catch (error) {
                    this.showError(`Error getting AI response: ${error.message}`);
                } finally {
                    this.isProcessing = false;
                    this.isSpeaking = false;
                    this.updateUI();
                    
                    // Resume listening after a short delay if in continuous mode
                    if (this.continuousMode) {
                        setTimeout(() => {
                            this.restartListening();
                        }, 1000);
                    }
                }
            }

            async getAIResponse(transcript) {
                // API URL for the chat endpoint
                const API_URL = '/api/chat';
                
                try {
                    const response = await fetch(API_URL, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            transcript: transcript,
                            history: this.history
                        })
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! status: ${response.status}`);
                    }

                    const data = await response.json();
                    this.history = data.history || this.history;
                    return data.response;
                } catch (error) {
                    // Fallback response for demo purposes
                    console.warn('API not available, using fallback response');
                    return this.getFallbackResponse(transcript);
                }
            }

            getFallbackResponse(transcript) {
                // Simple fallback responses for demo
                const responses = [
                    "That's interesting! Can you tell me more about that?",
                    "Great job speaking English! What else would you like to talk about?",
                    "I heard you say: '" + transcript + "'. That's wonderful! What's your favorite thing to do?",
                    "You're doing so well! Can you use that word in a different sentence?",
                    "Excellent! Let's practice some more. What did you do today?"
                ];
                return responses[Math.floor(Math.random() * responses.length)];
            }

            async speakResponse(text) {
                return new Promise(async (resolve, reject) => {
                    try {
                        // Stop any currently playing audio
                        if (this.currentAudio) {
                            this.currentAudio.pause();
                            this.currentAudio = null;
                        }

                        // Try ElevenLabs TTS first
                        try {
                            const response = await fetch('/api/tts', {
                                method: 'POST',
                                headers: {
                                    'Content-Type': 'application/json',
                                },
                                body: JSON.stringify({ text: text })
                            });

                            if (response.ok) {
                                // ElevenLabs TTS worked
                                const audioBlob = await response.blob();
                                const audioUrl = URL.createObjectURL(audioBlob);
                                this.currentAudio = new Audio(audioUrl);

                                this.currentAudio.onended = () => {
                                    URL.revokeObjectURL(audioUrl);
                                    resolve();
                                };

                                this.currentAudio.onerror = (event) => {
                                    URL.revokeObjectURL(audioUrl);
                                    reject(new Error('Audio playback error'));
                                };

                                await this.currentAudio.play();
                                return; // Success, exit here
                            } else {
                                throw new Error(`TTS API error: ${response.status}`);
                            }
                        } catch (apiError) {
                            console.log('ElevenLabs TTS failed, using browser TTS fallback:', apiError.message);
                            
                            // Fallback to browser TTS
                            if (window.speechSynthesis.speaking) {
                                window.speechSynthesis.cancel();
                            }

                            const utterance = new SpeechSynthesisUtterance(text);
                            utterance.rate = 0.8;
                            utterance.pitch = 1.1;
                            utterance.volume = 1;

                            // Try to use a child-friendly voice
                            const voices = window.speechSynthesis.getVoices();
                            const femaleVoice = voices.find(voice => 
                                voice.name.includes('Female') || 
                                voice.name.includes('Karen') ||
                                voice.name.includes('Susan') ||
                                voice.name.includes('Samantha')
                            ) || voices.find(voice => voice.lang.startsWith('en'));

                            if (femaleVoice) {
                                utterance.voice = femaleVoice;
                            }

                            utterance.onend = () => {
                                resolve();
                            };

                            utterance.onerror = (event) => {
                                reject(new Error(`Browser TTS error: ${event.error}`));
                            };

                            window.speechSynthesis.speak(utterance);
                        }

                    } catch (error) {
                        reject(error);
                    }
                });
            }

            stopSpeaking() {
                // Stop ElevenLabs audio if playing
                if (this.currentAudio) {
                    this.currentAudio.pause();
                    this.currentAudio = null;
                }
                
                // Stop browser TTS if playing
                if (window.speechSynthesis.speaking) {
                    window.speechSynthesis.cancel();
                }
                
                this.isSpeaking = false;
                this.updateUI();
                
                // Resume listening if in continuous mode
                if (this.continuousMode) {
                    setTimeout(() => {
                        this.restartListening();
                    }, 500);
                }
            }

            addMessage(role, text) {
                const messageEl = document.createElement('div');
                messageEl.className = `message ${role}`;
                messageEl.innerHTML = `
                    <div class="role">${role === 'user' ? 'You' : 'Genie'}:</div>
                    <div>${text}</div>
                `;
                this.conversationEl.appendChild(messageEl);
                this.conversationEl.scrollTop = this.conversationEl.scrollHeight;
            }

            clearConversation() {
                this.conversationEl.innerHTML = '';
                this.history = [];
                this.hideError();
            }

            updateUI() {
                let statusText = '';
                let statusClass = '';

                if (this.continuousMode && !this.isSpeaking && !this.isProcessing) {
                    statusText = 'üé§ Listening continuously... Speak anytime!';
                    statusClass = 'listening';
                    this.micButton.textContent = '‚èπÔ∏è';
                    this.micButton.classList.add('active');
                    this.micButton.classList.remove('listening');
                } else if (this.isListening && !this.isSpeaking && !this.isProcessing) {
                    statusText = 'üé§ Listening... Speak now!';
                    statusClass = 'listening';
                    this.micButton.textContent = '‚èπÔ∏è';
                    this.micButton.classList.add('listening');
                    this.micButton.classList.remove('active');
                } else if (this.isSpeaking) {
                    statusText = 'üîä Genie is speaking...';
                    statusClass = 'speaking';
                    this.micButton.textContent = 'üîä';
                    this.micButton.classList.remove('listening', 'active');
                } else if (this.isProcessing) {
                    statusText = 'ü§î Thinking... <span class="loading"></span>';
                    statusClass = 'processing';
                    this.micButton.textContent = '‚è≥';
                    this.micButton.classList.remove('listening', 'active');
                } else {
                    statusText = 'Click the microphone to start continuous listening!';
                    statusClass = '';
                    this.micButton.textContent = 'üé§';
                    this.micButton.classList.remove('listening', 'active');
                }

                this.statusEl.innerHTML = statusText;
                this.statusEl.className = `status ${statusClass}`;
            }

            showError(message) {
                this.errorEl.textContent = message;
                this.errorEl.style.display = 'block';
            }

            hideError() {
                this.errorEl.style.display = 'none';
            }
        }

        // Initialize the app when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceTutor();
        });

        // Load voices when they're available
        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = () => {
                // Voices are now loaded
            };
        }
    </script>
</body>
</html>